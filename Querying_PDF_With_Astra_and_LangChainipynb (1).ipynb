{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quickstart: Querying PDF With Astra and LangChain\n",
        "\n",
        "### A question-answering demo using Astra DB and LangChain, powered by Vector Search"
      ],
      "metadata": {
        "id": "xrfCJ3etcTHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre-requisites:\n",
        "\n",
        "You need a **_Serverless Cassandra with Vector Search_** database on [Astra DB](https://astra.datastax.com) to run this demo. As outlined in more detail [here](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html#_prepare_for_using_your_vector_database), you should get a DB Token with role _Database Administrator_ and copy your Database ID: these connection parameters are needed momentarily.\n",
        "\n",
        "You also need an [OpenAI API Key](https://cassio.org/start_here/#llm-access) for this demo to work.\n",
        "\n",
        "#### What you will do:\n",
        "\n",
        "- Setup: import dependencies, provide secrets, create the LangChain vector store;\n",
        "- Run a Question-Answering loop retrieving the relevant headlines and having an LLM construct the answer."
      ],
      "metadata": {
        "id": "pdIROnX3WEqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken langchain-community"
      ],
      "metadata": {
        "id": "R4GyaOHEWFDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ab06ce-0e43-42fb-f948-384e3d98489e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the packages you'll need:"
      ],
      "metadata": {
        "id": "-Vpxq4TRckcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain components to use\n",
        "from langchain_community.vectorstores import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# Support for dataset retrieval with Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
        "# you will also initialize the DB connection:\n",
        "import cassio"
      ],
      "metadata": {
        "id": "AVFnEzH_asaY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbfNkGwSdNrn",
        "outputId": "84b3b2df-5b0a-4ddd-f6ca-f3189f1dee2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/232.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "zvpsVFAKfZYl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup\n",
        "### Database setup and key (astra Db token and astra db Id)"
      ],
      "metadata": {
        "id": "Wv9o8Bj8flMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = \" take from website from db\" # enter the \"AstraCS:...\" string found in in your Token JSON file\n",
        "ASTRA_DB_ID = \" create your id from website \" # enter your Database ID\n",
        "\n",
        "OPENAI_API_KEY = \" insert your own\" # enter your OpenAI key"
      ],
      "metadata": {
        "id": "uDXGlFfsfsZ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('starai.pdf')"
      ],
      "metadata": {
        "id": "yg7-3RVUgOG2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ],
      "metadata": {
        "id": "Rj9bzUvLgfP9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "LPAEhy5ugwmB",
        "outputId": "d821d0a6-7510-4733-de98-debb74e57dfe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'From Statistical Relational to Neural-Symbolic Artiﬁcial Intelligence\\nLuc De Raedt1;2,Sebastijan Duman ˇci´c1,Robin Manhaeve1and Giuseppe Marra1\\n1KU Leuven, Department of Computer Science and Leuven.AI\\n2¨Orebro University, Center for Applied Autonomous Sensor Systems\\nfluc.deraedt, sebastian.dumancic, robin.manhaeve, giuseppe.marrag@kuleuven.be\\nAbstract\\nNeural-symbolic and statistical relational artiﬁcial\\nintelligence both integrate frameworks for learning\\nwith logical reasoning. This survey identiﬁes sev-\\neral parallels across seven different dimensions be-\\ntween these two ﬁelds. These cannot only be used\\nto characterize and position neural-symbolic artiﬁ-\\ncial intelligence approaches but also to identify a\\nnumber of directions for further research.\\n1 Introduction\\nThe integration of learning and reasoning is one of the key\\nchallenges in artiﬁcial intelligence and machine learning today,\\nand various communities have been addressing it. That is\\nespecially true for the ﬁeld of neural-symbolic computation\\n(NeSy) [Besold et al., 2017; d’Avila Garcez et al., 2019 ],\\nwhere the goal is to integrate symbolic reasoning and neural\\nnetworks. NeSy already has a long tradition, and it has\\nrecently attracted a lot of attention from various communities\\n(cf. the keynotes of Yoshua Bengio and Henry Kautz on this\\ntopic at AAAI 2020).\\nAnother domain that has a rich tradition in integrating\\nlearning and reasoning is that of statistical relational learning\\nand artiﬁcial intelligence (StarAI) [Getoor and Taskar, 2007;\\nDe Raedt et al., 2016 ]. But rather than focusing on integrating\\nlogic and neural networks, it is centred around the question\\nof integrating logic with probabilistic reasoning, more speciﬁ-\\ncally probabilistic graphical models. Despite the common in-\\nterest in combining symbolic reasoning with a basic paradigm\\nfor learning, i.e., probabilistic graphical models or neural net-\\nworks, it is surprising that there are not more interactions\\nbetween these two ﬁelds.\\nThis discrepancy is the key motivation behind this sur-\\nvey: it aims at pointing out the similarities between these\\ntwo endeavours and in this way it wants to stimulate cross-\\nfertilization. In doing so, we start from the literature on\\nStarAI, following the key concepts and techniques outlined in\\na number of textbooks and tutorials such as [Russell, 2015;\\nDe Raedt et al., 2016 ], because it turns out that the same\\nissues and techniques that arise in StarAI apply to NeSy as\\nwell. As the key contribution of this survey, we identify\\nseven dimensions that these ﬁelds have in common and that\\ncan be used to categorize both StarAI and NeSy approaches.These seven dimensions are concerned with (1) directed vs\\nundirected models, (2) model vs proof-based inference, (3)\\nintegrating logic with probability and/or neural computation,\\n(4) logical semantics, (5) learning parameters or structure,\\n(6) representing entities as symbols or sub-symbols, and (7)\\nthe type of logic used. We provide evidence for our claim\\nby positioning a wide variety of StarAI and NeSy systems\\nalong these dimensions and pointing out analogies between\\nthem. This provides not only new insights into the relation-\\nships between StarAI and NeSy, but it also allows one to carry\\nover and adapt techniques from one ﬁeld to another. Thus\\nthe insights provided in this paper can be used to create new\\nopportunities for cross-fertilization between StarAI and NeSy,\\nby focusing on those dimensions that have not been fully ex-\\nploited yet. Of course, there are also important differences\\nbetween StarAI and NeSy, the most important one being that\\nthe former operates more at the symbolic level, lending itself\\nnaturally to explainable AI, while the latter operates more\\nat the sub-symbolic level, lending itself more naturally for\\ncomputer vision and natural language processing.\\nUnlike some other recent surveys or perspectives on neural-\\nsymbolic computation [Besold et al., 2017; d’Avila Garcez et\\nal., 2019 ], the present survey limits itself to a logical and prob-\\nabilistic perspective, which it inherits from StarAI, and to de-\\nvelopments in neural-symbolic computation that are consistent\\nwith this perspective. Furthermore, it focuses on representative\\nand prototypical systems rather than aiming at completeness\\n(which would not be possible given the fast developments in\\nthe ﬁeld). Another early overview of neural-symbolic compu-\\ntation is that of [Bader and Hitzler, 2005 ]. Unlike the present\\nsurvey it focuses very much on a logical and a reasoning per-\\nspective. Today, the focus has shifted very much to learning.\\nThe following sections of the paper each describe one di-\\nmension. We summarize various neural-symbolic approaches\\nalong these dimensions in Table 1. For ease of writing, we\\ndo not always repeat the references to these approaches in the\\npaper, the table mentions the key reference for each of them.\\n2 Directed vs Undirected\\nWithin the graphical model community there is a distinction\\nbetween the directed andundirected graphical models [Koller\\nand Friedman, 2009 ], which has led to two distinct types of\\nStarAI systems. The ﬁrst generalizes directed models, and\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4943resembles Bayesian networks; the second generalizes undi-\\nrected models like Markov networks or random ﬁelds. The\\nkey difference between the two is that the ﬁrst class of mod-\\nels indicates a natural direction (sometimes the term “causal”\\nis used) between the different random variables, while the\\nsecond one does not.\\nIn StarAI, the ﬁrst category includes well-known represen-\\ntations such as plate notation [Koller and Friedman, 2009 ],\\nprobabilistic relational models (PRMs) [Friedman et al. , 1999 ],\\nprobabilistic logic programs (PLPs) [De Raedt and Kimmig,\\n2015 ], and Bayesian logic programs (BLPs) [Kersting and\\nDe Raedt, 2007 ]. Today the most typical and popular rep-\\nresentatives of this category are the probabilistic (logic) pro-\\ngrams. The second category includes Markov Logic Networks\\n(MLNs) [Richardson and Domingos, 2006 ]and Probabilistic\\nSoft Logic (PSL) [Bach et al., 2017 ]. They specify a set of\\nweighted constraints, clauses or formulae.\\nFrom a logical perspective, the difference amounts to using\\na form of deﬁnite clauses (as in the programming language\\nProlog) versus the use of full clausal logic or even ﬁrst order\\nlogic. On the one hand, a deﬁnite clause is an expression of the\\nformh b1^:::^bnwherehand thebiare logical atoms of\\nthe formp(t1;:::;t m), withpbeing a predicate of arity mand\\nthetibeing terms, that is, constants, variables, or structured\\nterms of the form f(t1;:::;t n), wherefis a functor and the\\ntiare again terms. On the other hand, full clausal logic also\\nallows for formulae of the form h1_:::_hm b1;:::;b n.\\nThe ﬁrst type of rule forms the basis of programming and\\ndatabase languages such as Prolog and Datalog. It is typically\\nused for forward or backward inference to prove that certain\\natoms hold. The second type of clause speciﬁes a more gen-\\neral relationship between two sets of atoms, the ones in the\\ncondition and in the conclusion part. While such clauses can\\nalso be used in (resolution) theorem provers, they can also be\\nviewed as constraints that relate these two sets of atoms as is\\ncommon in Answer Set Programming [Gebser et al., 2012 ].\\nThis difference reﬂects the kind of knowledge that the user has\\nabout the problem. With directed models, one can express that\\na set of variables has a direct “causal” inﬂuence on another\\none, while with undirected ones one expresses a kind of (soft)\\nconstraints on a set of variables, that is, that the variables are\\nrelated to one another. More details on these connections can\\nbe found in [De Raedt et al., 2016 ].\\nBorrowing this view from StarAI, we can devise a ﬁrst di-\\nmension for neural-symbolic approaches, which relies entirely\\non the logical perspective outlined above.\\nThe ﬁrst category includes systems which retain the directed\\nnature of logical inference as they exploit backward chaining.\\nThe most prominent members of this category are NeSy sys-\\ntems based on Prolog or Datalog, such as Neural Theorem\\nProvers (NTPs) [Rockt ¨aschel and Riedel, 2017 ], NLProlog\\n[Weber et al., 2019 ], DeepProbLog [Manhaeve et al., 2018 ]\\nand DiffLog [Siet al., 2019 ]. Lifted Relational Neural Net-\\nworks (LRNNs) [ˇSourek et al., 2018 ]and@ILP[Evans and\\nGrefenstette, 2018 ]are other examples of non-probabilistic\\ndirected models, where deﬁnite clauses are compiled into a\\nneural network architecture in a forward chaining fashion. The\\nsystems that imitate logical reasoning with tensor calculus,\\nNeural Logic Programming (NeuralLP) [Yang et al., 2017 ]and Neural Logic Machines (NLM) [Dong et al., 2019 ], are\\nlikewise instances of directed logic.\\nThe undirected NeSy approaches consider logic as a con-\\nstraint on the behaviour of a predictive model. A large\\ngroup of approaches, including Semantic Based regularization\\n(SBR) [Diligenti et al., 2017 ], Logic Tensor Networks(LTN)\\n[Donadello et al., 2017 ]and Semantic Loss (SL) [Xuet al.,\\n2018 ], exploits logical knowledge as a soft constraint over\\nthe hypothesis space in a way that favours solutions con-\\nsistent with the encoded knowledge. SBR and LTN imple-\\nment predicates as neural networks and translates the pro-\\nvided logical formulas into a real valued regularization by\\nmeans of fuzzy logic, while SL uses marginal probabilities\\nof the target atoms to deﬁne the regularization term and re-\\nlies on arithmetic circuits [Darwiche, 2011 ]to evaluate it\\nefﬁciently. Similarly, another group of approaches, including\\nNeural Markov Logic Networks (NMLN) [Marra and Ku ˇzelka,\\n2019 ]and Relational Neural Machines (RNM) [Marra et al.,\\n2020 ]extend MLNs, allowing factors to be implemented\\nas neural architectures. Finally, [Rockt ¨aschel et al., 2015;\\nDemeester et al., 2016 ]compute ground atoms scores as dot\\nproducts between relation and entities embeddings; implica-\\ntion rules are then translated into a logical loss by means of a\\ncontinuous relaxation of the implication operator.\\n3 Model-based vs Proof-based Inference\\nThe distinction between directed and undirected models is\\nclosely related to the distinction between a model-theoretic\\nand proof-theoretic approach to inference. This is clear when\\nlooking at the difference between Answer Set Programming\\nand the programming language Prolog. In the model theoretic\\nperspective, one ﬁrst grounds out the clauses in the theory and\\nthen calls a SAT solver (possibly after breaking cycles), while\\nin a proof-theoretic perspective one performs a sequence of\\ninference steps in order to obtain a proof.\\nGrounding is the step whereby a clause c(or formula) con-\\ntaining variablesfV1;:::;V kgis replaced by all instances c\\x12\\nwhere\\x12is a substitutionfV1=c1;:::V k=ckgand theciare\\nconstants (or other ground terms) appearing in the domain.\\nThe resulting clause c\\x12is that obtained by simultaneously\\nreplacing all variables by the corresponding constants. Usu-\\nally the grounding process is optimised in order to obtain\\nonly those ground clauses that are relevant for the considered\\ninference task.\\nMany StarAI systems use logic as a kind of template to\\nground out the relational model in order to obtain a grounded\\nmodel and perform inference. This grounded model can be a\\ngraphical model, or alternatively, a ground weighted logical\\ntheory on which traditional inference methods apply, such\\nas belief propagation or weighted model counting. This is\\nused in well known systems such as MLNs, PSL, BLPs, and\\nPRMs. Some systems like PRMs and BLPs additionally use\\naggregates, or combining rules, in order to combine multiple\\nconditional probability distributions into one using, e.g., noisy-\\nor.\\nAlternatively, one can follow a proof or trace based ap-\\nproach to deﬁne the probability distribution and perform infer-\\nence. This is akin to what happens in probabilistic program-\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4944ming (cf. also [Russell, 2015 ]), in StarAI frameworks such as\\nPLPs, probabilistic databases [Van den Broeck et al. , 2017 ]\\nand probabilistic uniﬁcation based grammars such as Stochas-\\ntic Logic Programs (SLPs) [Muggleton, 1996 ]. Just like pure\\nlogic supports the model-theoretic and proof-theoretic per-\\nspectives, both perspectives have been explored in parallel for\\nsome of the probabilistic logic programming languages such\\nas ICL [Poole, 2008 ]and ProbLog [Fierens et al., 2015 ].\\nThese two perspectives carry over to the neural-symbolic\\nmethods. Approaches like NTPs, DeepProblog, @ILP and\\nDiffLog are proof-based. The probabilities or certainties that\\nthese systems output are based on the enumerated proofs,\\nand they are also able to learn how to combine them. In\\ncontrast, approaches of LRNN, LTNs, RNM, NMLN, NLM\\nand NeuralLP are all based on the model-theoretic perspective.\\nLearning in these models is done through learning the (shared)\\nparameters over the ground model and inference is based on\\npossible groundings of the model.\\n4 Logic vs Probability vs Neural\\nWhen two paradigms are integrated, examining which of the\\nbase paradigms are preserved, and to which extent, tells us a lot\\nabout the strengths and weaknesses of the resulting paradigm.\\nIn StarAI, the traditional knowledge-based model construction\\napproach is to use the logic only to generate a probabilistic\\ngraphical model. Thus the graphical model can be used to de-\\nﬁne the semantics of the model and also to perform inference.\\nThis can make it more difﬁcult to understand the effects of ap-\\nplying logical inference rules such as resolution. For instance,\\nin MLNs the addition of the resolvent of two weighted rules,\\nmakes it hard to predict the effect on the distribution.\\nOn the other hand, the opposite holds for PLPs and its\\nvariants. While it is clear what the effect of a logical operation\\nis, it is often harder to directly identify and exploit properties\\nsuch as conditional or contextual independencies, which are\\nneeded for efﬁcient probabilistic inference.\\nThe position on the spectrum between logic and probability\\nhas a profound inﬂuence on the properties of the underlying\\nmodel. For NeSy, the spectrum involves not only logic and\\nneural networks, but also probability. It has been argued\\nthat when combining different perspectives in one model or\\nframework, such as neural, logic and probabilistic ones, it is\\ndesirable to have the originals or base paradigms as a special\\ncase, see also [De Raedt et al., 2019 ].\\nThe vast majority of current NeSy approaches focuses on\\nthe neural aspect (i.e., they originated as a fully neural method\\nto which logical components have been added). Some of these\\napproaches like LTNs and TensorLog [Cohen et al., 2017 ]pur-\\nsue a kind of knowledge-based model construction approach\\nin which the logic is compiled away into the neural network\\narchitecture. A different family of NeSy approaches, which\\nincludes SL and SBR, turns the logic into a regularization\\nfunction to provide a penalty whenever the desired logical\\ntheory or constraints are violated. This leads to the logic being\\ncompiled into the weights of the trained neural network.\\nA small number of NeSy methods do retain the focus on\\nlogic. Some of these methods start from existing logic (pro-\\ngramming) frameworks and extend them with primitives thatallow them to interface with neural networks and allow for\\ndifferentiable operations. Examples include DeepProbLog and\\nDiffLog. Other methods instead take an existing framework\\nand turn it into a differentiable version. The key inference\\nconcepts are mapped onto an analogous concept that behaves\\nidentically for the edge cases, but is continuous and differen-\\ntiable in non-deterministic cases. Such methods include @ILP,\\n@4[Boˇsnjak et al., 2017 ]and NTPs.\\nAn aspect that signiﬁcantly aids in developing a common\\nframework, and analysing its properties, is the development\\nof an intermediate representation language that can serve as\\na kind of assembly language [Zuidberg Dos Martires et al.,\\n2019 ]. One such idea concerns performing probabilistic infer-\\nence by mapping it onto a weighted model counting (WMC)\\nproblem. This can then in turn be solved by compiling it into\\na structure (e.g. an arithmetic circuit) that allows for efﬁcient\\ninference. This has the added beneﬁt that this structure is\\ndifferentiable, which can facilitate the integration between\\nlogic based systems and neural networks. DeepProbLog, for\\nexample, uses this approach.\\n5 Semantics\\nTraditionally, StarAI combines two semantics: a logical and a\\nprobabilistic one. In the logical semantics, atoms are assigned\\na truth value in the ftrue; falseg set (i.e.f0;1g). In a proba-\\nbilistic semantics, probability is deﬁned as a measure over sets\\nof possible worlds, where each possible world is an assignment\\nof values to the random variables. This implies that a proba-\\nbilistic logic semantics deﬁnes probability distributions over\\nground logical interpretations, that is, over sets of ground facts.\\nProminent examples in StarAI are ProbLog (from the directed\\nside) and MLNs (from the undirected one). Incorporating\\nprobabilistic semantics into a logical one is natural when one\\nwants to perform logical reasoning under uncertainty. More-\\nover, it “only” extends Boolean logic with probabilities, thus\\nit preserves the original logical semantics. However, this ex-\\ntension comes at the price of more complex inference, which\\nmakes probabilistic StarAI models intractable in large scale\\ndomains.\\nAnother approach is to turn the logical operators into real-\\nvalued functions, and in doing so relax the Boolean truth\\nvalues to the continuous [0;1]interval. This introduces the se-\\nmantics of fuzzy logic (or soft logic), which is mathematically\\ngrounded in the t-norm theory. The fuzzy semantics can be\\nused alone or in conjunction with the probabilistic one (e.g.\\n[Bach et al., 2017 ]). The algebraic and geometric properties of\\nt-norms (including especially convexity and differentiability)\\nresults in a reduction in the complexity of logical and/or prob-\\nabilistic inference. However, differently from the probabilistic\\ncase, the semantics of the original Boolean theory is not pre-\\nserved. Indeed, the fuzziﬁcation procedure can introduce unde-\\nsirable effects. In particular, improper choices in the fuzziﬁca-\\ntion could lead to behaviours that are different from the ones\\nin the original theory [Giannini et al., 2018 ]and particular\\nattention should be paid to assessing that any desired property\\nis preserved. For example, when translating the implication\\nA!Bwith its fuzzy material implication (i.e. :A_B), one\\nmay lose the transitivity property (e.g. the material implication\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4945in the minimum logic). Another class of anomalies concerns\\nthe way t-norms behave when aggregating a large number of\\nfuzzy truth degrees. An example is the n-ary Łukasiewicz\\nstrong disjunction F\\x08(x1;:::;x n) =min(1;x1+\\x01\\x01\\x01+xn).\\nIt can evaluate to 1 (i.e. true) also when all xiare very small\\n(i.e. false), e.g. n= 10 andxi= 0:1. The use of this operator\\nwould lead to poor approximations when disjointing multiple\\natoms, e.g. in existentially quantiﬁed formulas or in the aggre-\\ngation of several alternative proofs. [van Krieken et al., 2020 ]\\nanalyse similar issues, also in connection to differentiability.\\nNeural-symbolic approaches can easily be categorized along\\nthe same lines. Neural enhancements of the logic semantics\\neither use neural networks to turn perceptive input to a logical\\natom, or relax the logical reasoning through tensor calculus.\\nAn instance of the former is ABL [Daiet al., 2019 ], which use\\nlogical abduction to provide the feedback for a neural model\\nprocessing the perceptive input. Tensor calculus approaches,\\nsuch as NLM and NeuralLP, interpret predicates as tensors\\ngrounded over all constants in a domain and interpret clauses\\nas a product of those matrices.\\nNeural enhancements of the probabilistic semantics usually\\nparameterize the underlying distribution in terms of neural\\ncomponents. In particular, DeepProbLog exploits neural pred-\\nicates to compute the probabilities of probabilistic facts as the\\noutput of neural computations over vectorial representations\\nof the constants, which is similar to SL in the propositional\\ncounterpart. NMLN and RNM use neural potentials in order\\nto implement factors (or their weights) as neural networks.\\n[Rockt ¨aschel et al., 2015 ]computes marginal probabilities as\\nlogistic functions over similarity measures between embed-\\ndings of entities and relations.\\nIn neural enhancements of the fuzzy semantics, neural net-\\nworks produce continuously-valued truth assignments. The\\ndifferentiability of the t-norms allows to easily integrate neu-\\nral frameworks. In particular, SBR and LTN turn atoms into\\nneural networks taking as inputs the feature representation\\nof the constants and returning the corresponding truth value.\\nSimilarly, in LRNN, @ILP, DiffLog and [Wang and Pan, 2019 ],\\nthe scores of the proofs are computed by using fuzzy logic\\nconnectives.\\nFinally, a large class of methods [Minervini et al., 2017;\\nDemeester et al., 2016; Cohen et al., 2017; Weber et al., 2019 ]\\nrelaxes logical statements in a numeric way, without giving\\nany other speciﬁc semantics. Here, atoms are assigned scores\\ninRcomputed by a neural scoring function over embeddings.\\nNumerical approximations are then applied either to combine\\nthese scores according to logical formulas or to aggregate\\nproofs scores. The resulting neural architecture is usually\\ndifferentiable and, thus, trained end-to-end. It is however hard\\nto interpret the numbers generated by such approaches.\\n6 Structure vs Parameter Learning\\nStarAI distinguishes between two types of learning: structure\\nlearning, which corresponds to learning the logical clauses of\\nthe model [Kok and Domingos, 2005 ], and parameter learning\\nin which the probabilities or weights of the clauses have to be\\nestimated [Gutmann et al., 2008; Lowd and Domingos, 2007 ].\\nThe former is typically achieved by means of a combinatorialsearch over the space of possible clauses, while in the latter\\none an expert user provides a set of informative clauses for\\nwhich only the probabilities have to be estimated.\\nLearning in NeSy approaches blurs this distinction and\\nis positioned somewhere mid-ground: the model structure\\nis learned though parameter learning. In contrast to StarAI\\nparameter learning in which the user carefully selects the\\ninformative clauses, the set of clauses in NeSy approaches is\\ntypically enumerated from the user-provided rule templates of\\npredeﬁned complexity. As such, the enumerated rules contain\\nnoisy and erroneous patterns that are corrected by learning the\\ncorresponding probabilities or weights. The structure learning\\nis therefore not performed explicitly as none of the given rules\\nis removed. While it is certainly possible to extract the most\\nimportant clauses, the inference is still performed considering\\nall the enumerated clauses. Examples of such systems include\\nNTPs,@ILP, DeepProbLog, NeuralLP and DiffLog. A related\\nway of learning the structure is that of program sketching,\\nin which a user provides a sketch of the target model and\\nleaves certain parts of the model unspeciﬁed. The learning\\ntask corresponds to ﬁlling the blanks. NeSy systems based on\\nsketching, such as DeepProbLog and @4, perform a simpliﬁed\\nversion of sketching in which they ﬁll in a single operation\\ninstead of an entire program.\\nA substantial number of approaches tries to leverage the\\nbest of both worlds. These ideas include using neural models\\nto guide the symbolic search [Kalyan et al., 2018; Ellis et\\nal., 2018a; Valkov et al., 2018 ], or using a neural model to\\nproduce a program that is then executed symbolically [Ellis et\\nal., 2018b; Mao et al., 2019 ].\\n7 Symbols vs Sub-symbols\\nPerhaps the biggest difference between StarAI and neural\\nmethods is how they represent entities. StarAI generally repre-\\nsents entities by constants (symbols). However, neural meth-\\nods are unable to represent symbols directly and exactly, and\\ntherefore represent them with sub-symbolic formats, such as\\nvectorized representations. For instance, vectorized represen-\\ntations can be created through one-hot encodings, inherent\\nnumerical properties of symbols (e.g. the pixel data of an\\nimage), or by learning a mapping from one-hot encodings to\\na dense feature space. This, of course, has an impact on the\\ngeneralizability of the system towards unseen entities, as no\\nvectorized representation is available for an unseen entity.\\nAn especially interesting aspect of NeSy methods is that\\nthey combine the best of both worlds by introducing a vari-\\nety of ways to combine symbols and sub-symbols for task\\nrepresentation and reasoning. The idea of mapping entities\\nonto sub-symbols is made very explicit in LTNs, where in\\na ﬁrst step, all symbols are replaced with sub-symbols. In\\nDeepProbLog, entities are represented using symbols, but they\\nsometimes have sub-symbolic representations that are only\\nused inside the neural networks. Similarly, in [Lippi and Fras-\\nconi, 2009 ]and RNM, MLNs are conditioned on a feature\\nrepresentation of constants (e.g. images, audio signals). Fi-\\nnally, among those models exploiting learned embeddings,\\nwe ﬁnd [Rockt ¨aschel et al., 2015; Minervini et al., 2017;\\nDemeester et al., 2016 ].\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4946A powerful and elegant mechanism for reasoning about\\nsymbols matching in logic is uniﬁcation. For instance, the\\natomic expressions p(a;Y)andp(X;b)can be uniﬁed using\\nthe substitutionfX=a;Y=bg. Uniﬁcation not only works\\nfor constants but also for structured terms f(t1;:::;t n)wheref\\nis a structured term and the tiare constants, variables or struc-\\ntured terms themselves. While uniﬁcation is not supported by\\nstandard neural networks, matching of the symbols can be per-\\nformed based on their similarity in embedding space. Entities\\nare typically embedded in some metric space, and represented\\nthrough their embeddings, that is, through sub-symbols. Rea-\\nsoning typically proceeds by performing algebraic operations\\n(such as vector addition) on these embeddings, and consider-\\ning the similarity between two entities by using their distance\\nin embedding space. It is quite interesting to see to what extent\\ncurrent neural-symbolic approaches support uniﬁcation on the\\none hand, and to what extent the use of embeddings has been\\nintegrated into the neural-symbolic logics as a kind of soft\\nequality or uniﬁcation\\nThis idea was implemented in NTPs and NLProlog as softor\\nweak uniﬁcation. In these systems, two entities can be uniﬁed\\nif they are similar, and not just if they are identical. As such,\\nthis system can interweave both symbols and sub-symbols\\nduring inference. For each entity, an embedding is learned and\\ntheir similarity is determined based on the distance between\\nthe embeddings using a radial basis function. However, this\\npotentially adds a lot of different proof paths, which can result\\nin computational issues for larger programs. This problem\\nwas solved in later iterations of the system [Minervini et al.,\\n2020 ].\\n8 Type of Logic\\nStarAI approaches have explored various types of logical rep-\\nresentations, following a natural ordering [De Raedt, 2008;\\nFlach, 1994 ]starting with propositional logic (symbols with-\\nout arguments), to relational logic (with only constants and\\nvariables as terms, without any structured terms) which forms\\nthe basis for the Datalog database language, to general ﬁrst\\norder logic, and then to logic programs as in the program-\\nming language Prolog. Logic programs are usually re-\\nstricted to deﬁnite clauses. The semantics of a deﬁnite\\nclause program is given by its least Herbrand model, the\\nset of all ground facts that are logically entailed by the pro-\\ngram. This contrasts with the standard semantics of ﬁrst order\\nlogic that would also allow for other models. This differ-\\nence carries over to StarAI, where probabilistic logic pro-\\ngrams and Markov Logic inherit their semantics from logic\\nprogramming, respectively ﬁrst order logic. This explains,\\nfor instance, why Markov Logic’s semantics boils down to\\na maximum entropy approach when a theory has multiple\\nmodels (such as a_b), cf. [De Raedt and Kimmig, 2015;\\nDe Raedt et al., 2016 ]for more details. On the other hand,\\nlogic programs are also the basis for the programming lan-\\nguage Prolog, which implies that they can be used to specify\\ntraditional programs such as sorting and data structures such\\nas lists through structured terms. This is relevant especially\\nfor those approaches to neural-symbolic computation that are\\nused to synthesize programs from examples.NeSy approaches follow the same natural expressivity order\\nof the underlying logics. For instance, SL focuses only on\\nthe propositional setting. On the other hand, @ILP, NTPs and\\nDiffLog are based on Datalog, which belongs to relational\\nlogic segment. LTNs and SBR use fuzzy logic to translate a\\ngeneral ﬁrst-order logic theory into a training objective, either\\nisolated or in conjunction with a supervised criterion. Just like\\nMarkov Logic, also RNM and NMLN use ﬁrst-order logic to\\ngenerate a random ﬁeld. Finally, DeepProbLog, NLProlog and\\nLRNN are examples of neural-symbolic logic programming\\nframeworks.\\nThe chosen type of logic has a signiﬁcant impact on infer-\\nence and learning. The more expressive a logic, the harder\\nthe inference and learning become. For instance, for structure\\nlearning, the space of possible clauses for structure learning\\ntypically becomes exponentially larger as a more expressive\\nclass of logic is used. At the same time, many theories re-\\nquire a certain level of representation expressivity and cannot\\nbe expressed using simpler types of logic. For instance, pro-\\ngrams cannot be represented using relational and propositional\\nrepresentations.\\n9 Open Challenges\\nTo conclude, we list a number of challenges for NeSy, which\\ndeserve, in our opinion, more attention.\\nSemantics The statistical relational AI community and the\\nprobabilistic graphical model communities have devoted a lot\\nof attention to the semantics of its models. This has resulted\\nin a number of clear choices (such as directed vs. undirected,\\ntrace-based vs. possible world [Russell, 2015 ]), with corre-\\nsponding strengths and weaknesses, which has allowed to clar-\\nify the relationships between the different models. Workshops\\nhave been held on that topic1. Furthermore, some researchers\\nhave investigated how to transform one type of model into\\nanother [Jaeger, 2008 ]. At the same time, the framework of\\nweight model counting has emerged as a common assembly\\nlanguage for inference in many of these languages. The situa-\\ntion in neural-symbolic computation today is very much that of\\nthe early days in statistical relational learning, in which there\\nwere many competing formalisms, (sometimes characterized\\nas the statistical relational learning alphabet soup). It would be\\ngreat to get more insight into the semantics of neural-symbolic\\napproaches and their relationships. This survey hopes to con-\\ntribute towards this goal.\\nProbabilistic reasoning Although relatively few methods\\nexplore the integration of logical and neural methods from a\\nprobabilistic perspective, we believe that a probabilistic ap-\\nproach is a very good way to integrate the two [De Raedt\\net al., 2019 ], but many open questions remain. Probabilis-\\ntic inference is computationally more expensive than other\\napproaches discussed in this paper. It would be interesting\\nin future work to determine exactly what the beneﬁt of this\\nprobabilistic approach is, and in which circumstances it arises.\\nFuzzy semantics The selection of the t-norm fuzzy logic\\nand the corresponding translation of the connectives is very\\nheterogeneous in the literature.It is often not well clear which\\n1For instance, https://pps2018.luddy.indiana.edu/\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4947Dimension 1\\nDimension 2 Dimension 3 Dimension 4 Dimension 5 Dimension 6 Dimension 7\\n(D)irected\\n(U)ndirected(M)odel-based\\n(P)roof -based(L)ogic\\n(P)robability\\n(N)eural(L)ogic\\n(P)robability\\n(F)uzzy(P)arameter\\n(S)tructure(S)ymbols\\n(Sub)symbols(P)ropositional\\n(R)elational\\n(FOL)\\n(LP)@ILP[Evans\\nand Grefenstette, 2018 ] D P L+N F P + S S R\\nDeepProbLog [Manhaeve et al., 2018 ] D P L+P+N P P S+Sub LP\\nDiffLog [Siet al., 2019 ] D P L+N F P+S S R\\nLRNN [ˇSourek et al., 2018 ] D P L+N F P+S S+Sub LP\\nLTN [Donadello et al., 2017 ] U M L+N F P Sub FOL\\nNeuralLP [Yang et al., 2017 ] D M L+N L P S R\\nNLM [Dong et al., 2019 ] D M L+N L P+S S R\\nNLProlog [Weber et al., 2019 ] D P L+P+N P P+S S+Sub LP\\nNMLN [Marra and Ku ˇzelka, 2019 ] U M L+P+N P P+S S+Sub FOL\\nNTP [Rockt ¨aschel and Riedel, 2017 ] D P L+N L P+S S+Sub R\\nRNM [Marra et al., 2020 ] U M L+P+N P P S+Sub FOL\\nSL[Xuet al., 2018 ] U M L+P+N P P S+Sub P\\nSBR [Diligenti et al., 2017 ] U M L+N F P Sub FOL\\nTensorlog [Cohen et al., 2017 ] D P L+N P P S+Sub R\\nTable 1: Taxonomy of a (non-exhaustive) list of NeSy models according to the 7 dimensions outlined in the paper.\\nproperties of Boolean logic a model is preserving, while there\\nis the general tendency to consider fuzzy logic a continu-\\nous surrogate of Boolean logic without considering the well-\\nknown differences in semantics. There is a clear need for\\nfurther studies in this ﬁeld. On one hand, one could want to\\ndeﬁne new models which are natively fuzzy, thus not requiring\\nthe translation from Boolean logic. On the other hand, an\\ninteresting research direction concerns the characterisation\\nof what is a good fuzzy approximation of Boolean logic in\\nrelation to a set of properties that one wishes to preserve.\\nApplications The current NeSy systems are not yet very\\nmature from an application perspective and there are no real\\nshowcase applications yet. However, there have been promis-\\ning proof-of-concepts in various ﬁelds. First, knowledge-\\nbase completion is a natural application for NeSy methods as\\nthe knowledge base is inherently symbolic and neural meth-\\nods can be leveraged to generalise over the facts and pre-\\ndict those that are missing [Rockt ¨aschel and Riedel, 2017;\\nDonadello et al., 2017 ]. Second, NeSy has contributed\\nto various computer vision tasks by incorporating back-\\nground knowledge in, for instance, image segmentation\\nand semantic image interpretation [Donadello et al. , 2017;\\nAlirezaie et al., 2019 ]. Lastly, NeSy methods were used\\nto aid natural language tasks such as question answering\\nand visual question answering [Weber et al., 2019; Yi et al.,\\n2018 ], where the latter is also closely related to the com-\\nputer vision domain. Some of the methods mentioned show\\nsome promising early results in the domain of inductive pro-\\ngramming [Evans and Grefenstette, 2018; Si et al., 2019;\\nRockt ¨aschel and Riedel, 2017 ], although they are still limited\\nwhen compared to standard inductive logic programming sys-\\ntems. Developing real-life applications of NeSy is one of themost challenging and pressing open questions for the ﬁeld.\\nStructure learning While signiﬁcant progress has been\\nmade on learning the structure of purely relational models\\n(without probabilities), learning StarAI models remains a ma-\\njor challenge due to the complexity of inference and the com-\\nbinatorial nature of the problem. Incorporating neural aspects\\ncomplicates the problem even more. NeSy methods have cer-\\ntainly shown potential for addressing this problem (Section 6),\\nbut the existing methods are still limited and mostly domain-\\nspeciﬁc which impedes their wide application. For instance,\\nthe current systems that support structure learning require user\\neffort to specify the clause templates or write a sketch of a\\nmodel.\\nScaling inference Scalable inference is a major challenge\\nfor StarAI and therefore also for NeSy approaches with an\\nexplicit logical or probabilistic reasoning component. Inves-\\ntigating to which extent neural methods can help with this\\nchallenge by means of lifted (exploiting symmetries in mod-\\nels) or approximate inference, as well as reasoning from the\\nintermediate representations [Abboud et al., 2020 ], are promis-\\ning future research directions.\\nData efﬁciency A major advantage of StarAI methods, as\\ncompared to neural ones, is their data efﬁciency – StarAI meth-\\nods can efﬁciently learn from small amounts of data, whereas\\nneural methods are data hungry. On the other hand, StarAI\\nmethods do not scale to big data sets, while neural methods can\\neasily handle them. We believe that understanding how these\\nmethods can help each other to overcome their complementary\\nweaknesses, is a promising research direction.\\nSymbolic representation learning The effectiveness of\\ndeep learning comes from the ability to change the representa-\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4948tion of the data so that the target task becomes easier to solve.\\nThe ability to change the representation on the symbolic level\\nas well would signiﬁcantly increase the capabilities of NeSy\\nsystems. This is a major open challenge for which neurally\\ninspired methods could help achieve progress [Cropper, 2019;\\nDuman ˇci´cet al., 2019 ].\\nAcknowledgements\\nRobin Manhaeve and Sebastijan Duman ˇci´c are funded by the\\nResearch Foundation-Flanders (FWO). This work has also\\nreceived funding from the European Research Council (ERC)\\nunder the European Union’s Horizon 2020 research and in-\\nnovation programme (grant agreement No [694980] SYNTH:\\nSynthesising Inductive Data Models) and the Wallenberg AI,\\nAutonomous Systems and Software Program (WASP) funded\\nby the Knut and Alice Wallenberg Foundation.\\nReferences\\n[Abboud et al., 2020 ]Ralph Abboud, ˙Ismail ˙Ilkan Ceylan, and\\nThomas Lukasiewicz. Learning to reason: Leveraging neural\\nnetworks for approximate DNF counting. In AAAI, 2020.\\n[Alirezaie et al., 2019 ]Marjan Alirezaie, Martin L ¨angkvist,\\nMichael Sioutis, and Amy Loutﬁ. Semantic referee: A\\nneural-symbolic framework for enhancing geospatial semantic\\nsegmentation. Semantic Web, 10, 2019.\\n[Bach et al., 2017 ]Stephen H. Bach, Matthias Broecheler, Bert\\nHuang, and Lise Getoor. Hinge-loss markov random ﬁelds and\\nprobabilistic soft logic. J. Mach. Learn. Res., 18, 2017.\\n[Bader and Hitzler, 2005 ]Sebastian Bader and Pascal Hitzler. Di-\\nmensions of neural-symbolic integration - A structured survey.\\nCoRR, abs/cs/0511042, 2005.\\n[Besold et al., 2017 ]Tarek R. Besold, Artur S. d’Avila Garcez, Se-\\nbastian Bader, Howard Bowman, Pedro M. Domingos, Pascal Hit-\\nzler, Kai-Uwe K ¨uhnberger, Lu ´ıs C. Lamb, Daniel Lowd, Priscila\\nMachado Vieira Lima, Leo de Penning, Gadi Pinkas, Hoifung\\nPoon, and Gerson Zaverucha. Neural-symbolic learning and rea-\\nsoning: A survey and interpretation. CoRR, abs/1711.03902,\\n2017.\\n[Boˇsnjak et al., 2017 ]Matko Bo ˇsnjak, Tim Rockt ¨aschel, Jason\\nNaradowsky, and Sebastian Riedel. Programming with a dif-\\nferentiable forth interpreter. In ICML, 2017.\\n[Cohen et al., 2017 ]William W. Cohen, Fan Yang, and Kathryn\\nMazaitis. Tensorlog: Deep learning meets probabilistic dbs. CoRR,\\nabs/1707.05390, 2017.\\n[Cropper, 2019 ]Andrew Cropper. Playgol: Learning programs\\nthrough play. In IJCAI 2019, 2019.\\n[Daiet al., 2019 ]Wang-Zhou Dai, Qiuling Xu, Yang Yu, and Zhi-\\nHua Zhou. Bridging machine learning and logical reasoning by\\nabductive learning. In NeurIPS, 2019.\\n[Darwiche, 2011 ]Adnan Darwiche. Sdd: A new canonical repre-\\nsentation of propositional knowledge bases. In IJCAI, 2011.\\n[d’Avila Garcez et al., 2019 ]Artur S. d’Avila Garcez, Marco Gori,\\nLu´ıs C. Lamb, Luciano Seraﬁni, Michael Spranger, and Son N.\\nTran. Neural-symbolic computing: An effective methodology for\\nprincipled integration of machine learning and reasoning. FLAP,\\n6, 2019.[De Raedt and Kimmig, 2015 ]Luc De Raedt and Angelika Kimmig.\\nProbabilistic (logic) programming concepts. Machine Learning,\\n100, 2015.\\n[De Raedt et al., 2016 ]Luc De Raedt, Kristian Kersting, Sriraam\\nNatarajan, and David Poole. Statistical Relational Artiﬁcial Intelli-\\ngence: Logic, Probability, and Computation. Morgan & Claypool\\nPublishers, 2016.\\n[De Raedt et al., 2019 ]Luc De Raedt, Robin Manhaeve, Sebastijan\\nDuman ˇci´c, Thomas Demeester, and Angelika Kimmig. Neuro-\\nsymbolic= neural+ logical+ probabilistic. In NeSy @ IJCAI, 2019.\\n[De Raedt, 2008 ]Luc De Raedt. Logical and relational learning.\\nSpringer, 2008.\\n[Demeester et al., 2016 ]Thomas Demeester, Tim Rockt ¨aschel, and\\nSebastian Riedel. Lifted rule injection for relation embeddings.\\nInEMNLP, 2016.\\n[Diligenti et al., 2017 ]Michelangelo Diligenti, Marco Gori, and\\nClaudio Sacc `a. Semantic-based regularization for learning and\\ninference. Artif. Intell., 244, 2017.\\n[Donadello et al., 2017 ]Ivan Donadello, Luciano Seraﬁni, and Ar-\\ntur S. d’Avila Garcez. Logic tensor networks for semantic image\\ninterpretation. In IJCAI, 2017.\\n[Dong et al., 2019 ]Honghua Dong, Jiayuan Mao, Tian Lin, Chong\\nWang, Lihong Li, and Denny Zhou. Neural logic machines. In\\nICLR, 2019.\\n[Duman ˇci´cet al., 2019 ]Sebastijan Duman ˇci´c, Tias Guns, Wannes\\nMeert, and Hendrik Blockeel. Learning relational representations\\nwith auto-encoding logic programs. In IJCAI, 2019.\\n[Ellis et al., 2018a ]Kevin Ellis, Lucas Morales, Mathias Sabl ´e-\\nMeyer, Armando Solar-Lezama, and Josh Tenenbaum. Learn-\\ning libraries of subroutines for neurally-guided bayesian program\\ninduction. In NeurIPS, 2018.\\n[Ellis et al., 2018b ]Kevin Ellis, Daniel Ritchie, Armando Solar-\\nLezama, and Josh Tenenbaum. Learning to infer graphics pro-\\ngrams from hand-drawn images. In NeurIPS, 2018.\\n[Evans and Grefenstette, 2018 ]Richard Evans and Edward Grefen-\\nstette. Learning explanatory rules from noisy data. J. Artif. Intell.\\nRes., 61, 2018.\\n[Fierens et al., 2015 ]Daan Fierens, Guy Van den Broeck, Joris\\nRenkens, Dimitar Shterionov, Bernd Gutmann, Ingo Thon, Gerda\\nJanssens, and Luc De Raedt. Inference and learning in probabilis-\\ntic logic programs using weighted boolean formulas. Theory and\\nPractice of Logic Programming, 15, 2015.\\n[Flach, 1994 ]Peter Flach. Simply Logical: Intelligent Reasoning by\\nExample. John Wiley & Sons, Inc., 1994.\\n[Friedman et al., 1999 ]Nir Friedman, Lise Getoor, Daphne Koller,\\nand Avi Pfeffer. Learning probabilistic relational models. In\\nIJCAI, 1999.\\n[Gebser et al., 2012 ]Martin Gebser, Roland Kaminski, Benjamin\\nKaufmann, and Torsten Schaub. Answer set solving in practice.\\nSynthesis lectures on artiﬁcial intelligence and machine learning ,\\n6, 2012.\\n[Getoor and Taskar, 2007 ]L. Getoor and B. Taskar, editors. An\\nIntroduction to Statistical Relational Learning. MIT Press, 2007.\\n[Giannini et al., 2018 ]Francesco Giannini, Michelangelo Diligenti,\\nMarco Gori, and Marco Maggini. On a convex logic fragment for\\nlearning and reasoning. IEEE TFS, 27, 2018.\\n[Gutmann et al., 2008 ]Bernd Gutmann, Angelika Kimmig, Kristian\\nKersting, and Luc De Raedt. Parameter learning in probabilistic\\ndatabases: A least squares approach. In ECML&PKDD, 2008.\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4949[Jaeger, 2008 ]Manfred Jaeger. Model-theoretic expressivity anal-\\nysis. In Luc De Raedt, Paolo Frasconi, Kristian Kersting, and\\nStephen Muggleton, editors, Probabilistic Inductive Logic Pro-\\ngramming - Theory and Applications, volume 4911 of LNCS.\\nSpringer, 2008.\\n[Kalyan et al., 2018 ]Ashwin Kalyan, Abhishek Mohta, Oleksandr\\nPolozov, Dhruv Batra, Prateek Jain, and Sumit Gulwani. Neural-\\nguided deductive search for real-time program synthesis from\\nexamples. In ICLR, 2018.\\n[Kersting and De Raedt, 2007 ]Kristian Kersting and Luc De Raedt.\\nBayesian logic programming: Theory and tool. In L. Getoor\\nand B. Taskar, editors, An introduction to Statistical Relational\\nLearning. MIT Press, 2007.\\n[Kok and Domingos, 2005 ]Stanley Kok and Pedro Domingos.\\nLearning the structure of markov logic networks. In ICML, 2005.\\n[Koller and Friedman, 2009 ]Daphne Koller and Nir Friedman.\\nProbabilistic Graphical Models - Principles and Techniques. MIT\\nPress, 2009.\\n[Lippi and Frasconi, 2009 ]Marco Lippi and Paolo Frasconi. Predic-\\ntion of protein beta-residue contacts by markov logic networks\\nwith grounding-speciﬁc weights. Bioinform., 25, 2009.\\n[Lowd and Domingos, 2007 ]Daniel Lowd and Pedro Domingos.\\nEfﬁcient weight learning for markov logic networks. In\\nECML&PKDD, 2007.\\n[Manhaeve et al., 2018 ]Robin Manhaeve, Sebastijan Duman ˇci´c,\\nAngelika Kimmig, Thomas Demeester, and Luc De Raedt. Deep-\\nproblog: Neural probabilistic logic programming. In NeurIPS,\\n2018.\\n[Mao et al., 2019 ]Jiayuan Mao, Chuang Gan, Pushmeet Kohli,\\nJoshua B. Tenenbaum, and Jiajun Wu. The neuro-symbolic con-\\ncept learner: Interpreting scenes, words, and sentences from natu-\\nral supervision. In ICLR, 2019.\\n[Marra and Ku ˇzelka, 2019 ]Giuseppe Marra and Ondrej Ku ˇzelka.\\nNeural markov logic networks. CoRR, abs/1905.13462, 2019.\\n[Marra et al., 2020 ]Giuseppe Marra, Michelangelo Diligenti,\\nFrancesco Giannini, Marco Gori, and Marco Maggini. Relational\\nneural machines. In ECAI in press, 2020.\\n[Minervini et al., 2017 ]Pasquale Minervini, Thomas Demeester,\\nTim Rockt ¨aschel, and Sebastian Riedel. Adversarial sets for\\nregularising neural link predictors. In UAI, 2017.\\n[Minervini et al., 2020 ]Pasquale Minervini, Matko Bo ˇsnjak, Tim\\nRockt ¨aschel, Sebastian Riedel, and Edward Grefenstette. Differ-\\nentiable reasoning on large knowledge bases and natural language.\\nInAAAI, 2020.\\n[Muggleton, 1996 ]Stephen Muggleton. Stochastic logic programs.\\nAdvances in inductive logic programming, 32, 1996.\\n[Poole, 2008 ]David Poole. The independent choice logic and be-\\nyond. In Probabilistic Inductive Logic Programming - Theory and\\nApplications, volume 4911 of LNCS. Springer, 2008.\\n[Richardson and Domingos, 2006 ]Matthew Richardson and Pe-\\ndro M. Domingos. Markov logic networks. Machine Learning,\\n62, 2006.\\n[Rockt ¨aschel and Riedel, 2017 ]Tim Rockt ¨aschel and Sebastian\\nRiedel. End-to-end differentiable proving. In NIPS, 2017.\\n[Rockt ¨aschel et al., 2015 ]Tim Rockt ¨aschel, Sameer Singh, and Se-\\nbastian Riedel. Injecting logical background knowledge into\\nembeddings for relation extraction. In NAACL HLT, 2015.[Russell, 2015 ]Stuart Russell. Unifying logic and probability. Com-\\nmunications of the ACM, 58, 2015.\\n[Siet al., 2019 ]Xujie Si, Mukund Raghothaman, Kihong Heo, and\\nMayur Naik. Synthesizing datalog programs using numerical\\nrelaxation. In IJCAI, 2019.\\n[Valkov et al., 2018 ]Lazar Valkov, Dipak Chaudhari, Akash Srivas-\\ntava, Charles A. Sutton, and Swarat Chaudhuri. Houdini: Lifelong\\nlearning as program synthesis. In NeurIPS, 2018.\\n[Van den Broeck et al., 2017 ]Guy Van den Broeck, Dan Suciu, et al.\\nQuery processing on probabilistic data: A survey. Foundations\\nand Trends® in Databases, 7, 2017.\\n[van Krieken et al., 2020 ]Emile van Krieken, Erman Acar, and\\nFrank van Harmelen. Analyzing differentiable fuzzy logic op-\\nerators. CoRR, abs/2002.06100, 2020.\\n[Wang and Pan, 2019 ]Wenya Wang and Sinno Jialin Pan. Integrat-\\ning deep learning with logic fusion for information extraction.\\nCoRR, abs/1912.03041, 2019.\\n[Weber et al., 2019 ]Leon Weber, Pasquale Minervini, Jannes\\nM¨unchmeyer, Ulf Leser, and Tim Rockt ¨aschel. Nlprolog: Rea-\\nsoning with weak uniﬁcation for question answering in natural\\nlanguage. In ACL, 2019.\\n[Xuet al., 2018 ]Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang,\\nand Guy Van den Broeck. A semantic loss function for deep\\nlearning with symbolic knowledge. In ICML, 2018.\\n[Yang et al., 2017 ]Fan Yang, Zhilin Yang, and William W Cohen.\\nDifferentiable learning of logical rules for knowledge base reason-\\ning. In NIPS, 2017.\\n[Yiet al., 2018 ]Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Tor-\\nralba, Pushmeet Kohli, and Josh Tenenbaum. Neural-symbolic\\nvqa: Disentangling reasoning from vision and language under-\\nstanding. In NeurIPS, 2018.\\n[Zuidberg Dos Martires et al., 2019 ]Pedro Zuidberg Dos Martires,\\nVincent Derkinderen, Robin Manhaeve, Wannes Meert, Angelika\\nKimmig, and Luc De Raedt. Transforming probabilistic programs\\ninto algebraic circuits for inference and learning. In Program\\nTransformations for ML Workshop at NeurIPS, 2019.\\n[ˇSourek et al., 2018 ]Gustav ˇSourek, V ojtech Aschenbrenner, Filip\\nZelezn ´y, Steven Schockaert, and Ondrej Ku ˇzelka. Lifted relational\\nneural networks: Efﬁcient learning of latent relational structures.\\nJ. Artif. Intell. Res., 62, 2018.\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4950'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the connection to your database:\n"
      ],
      "metadata": {
        "id": "SVww_d7gg_hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ],
      "metadata": {
        "id": "lXqwdOkhg8Vn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Create the LangChain embedding and LLM objects for later usage:"
      ],
      "metadata": {
        "id": "CPDlj8FihZN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk4nOuMPhcD9",
        "outputId": "a7468921-9558-41af-bf36-93b916aee734"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1961253011.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
            "/tmp/ipython-input-1961253011.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create your LangChain vector store ... backed by Astra DB!"
      ],
      "metadata": {
        "id": "Z9b7MuJ3htgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None,\n",
        ")"
      ],
      "metadata": {
        "id": "ZD2DrvpkhsS9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "fEmfu1GEh_uz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAhn4-4AiMea",
        "outputId": "cdb01ede-b029-450d-869d-93bf522f1ecf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['From Statistical Relational to Neural-Symbolic Artiﬁcial Intelligence\\nLuc De Raedt1;2,Sebastijan Duman ˇci´c1,Robin Manhaeve1and Giuseppe Marra1\\n1KU Leuven, Department of Computer Science and Leuven.AI\\n2¨Orebro University, Center for Applied Autonomous Sensor Systems\\nfluc.deraedt, sebastian.dumancic, robin.manhaeve, giuseppe.marrag@kuleuven.be\\nAbstract\\nNeural-symbolic and statistical relational artiﬁcial\\nintelligence both integrate frameworks for learning\\nwith logical reasoning. This survey identiﬁes sev-\\neral parallels across seven different dimensions be-\\ntween these two ﬁelds. These cannot only be used\\nto characterize and position neural-symbolic artiﬁ-\\ncial intelligence approaches but also to identify a\\nnumber of directions for further research.\\n1 Introduction',\n",
              " 'to characterize and position neural-symbolic artiﬁ-\\ncial intelligence approaches but also to identify a\\nnumber of directions for further research.\\n1 Introduction\\nThe integration of learning and reasoning is one of the key\\nchallenges in artiﬁcial intelligence and machine learning today,\\nand various communities have been addressing it. That is\\nespecially true for the ﬁeld of neural-symbolic computation\\n(NeSy) [Besold et al., 2017; d’Avila Garcez et al., 2019 ],\\nwhere the goal is to integrate symbolic reasoning and neural\\nnetworks. NeSy already has a long tradition, and it has\\nrecently attracted a lot of attention from various communities\\n(cf. the keynotes of Yoshua Bengio and Henry Kautz on this\\ntopic at AAAI 2020).\\nAnother domain that has a rich tradition in integrating',\n",
              " 'recently attracted a lot of attention from various communities\\n(cf. the keynotes of Yoshua Bengio and Henry Kautz on this\\ntopic at AAAI 2020).\\nAnother domain that has a rich tradition in integrating\\nlearning and reasoning is that of statistical relational learning\\nand artiﬁcial intelligence (StarAI) [Getoor and Taskar, 2007;\\nDe Raedt et al., 2016 ]. But rather than focusing on integrating\\nlogic and neural networks, it is centred around the question\\nof integrating logic with probabilistic reasoning, more speciﬁ-\\ncally probabilistic graphical models. Despite the common in-\\nterest in combining symbolic reasoning with a basic paradigm\\nfor learning, i.e., probabilistic graphical models or neural net-\\nworks, it is surprising that there are not more interactions\\nbetween these two ﬁelds.',\n",
              " 'for learning, i.e., probabilistic graphical models or neural net-\\nworks, it is surprising that there are not more interactions\\nbetween these two ﬁelds.\\nThis discrepancy is the key motivation behind this sur-\\nvey: it aims at pointing out the similarities between these\\ntwo endeavours and in this way it wants to stimulate cross-\\nfertilization. In doing so, we start from the literature on\\nStarAI, following the key concepts and techniques outlined in\\na number of textbooks and tutorials such as [Russell, 2015;\\nDe Raedt et al., 2016 ], because it turns out that the same\\nissues and techniques that arise in StarAI apply to NeSy as\\nwell. As the key contribution of this survey, we identify\\nseven dimensions that these ﬁelds have in common and that',\n",
              " 'issues and techniques that arise in StarAI apply to NeSy as\\nwell. As the key contribution of this survey, we identify\\nseven dimensions that these ﬁelds have in common and that\\ncan be used to categorize both StarAI and NeSy approaches.These seven dimensions are concerned with (1) directed vs\\nundirected models, (2) model vs proof-based inference, (3)\\nintegrating logic with probability and/or neural computation,\\n(4) logical semantics, (5) learning parameters or structure,\\n(6) representing entities as symbols or sub-symbols, and (7)\\nthe type of logic used. We provide evidence for our claim\\nby positioning a wide variety of StarAI and NeSy systems\\nalong these dimensions and pointing out analogies between\\nthem. This provides not only new insights into the relation-',\n",
              " 'by positioning a wide variety of StarAI and NeSy systems\\nalong these dimensions and pointing out analogies between\\nthem. This provides not only new insights into the relation-\\nships between StarAI and NeSy, but it also allows one to carry\\nover and adapt techniques from one ﬁeld to another. Thus\\nthe insights provided in this paper can be used to create new\\nopportunities for cross-fertilization between StarAI and NeSy,\\nby focusing on those dimensions that have not been fully ex-\\nploited yet. Of course, there are also important differences\\nbetween StarAI and NeSy, the most important one being that\\nthe former operates more at the symbolic level, lending itself\\nnaturally to explainable AI, while the latter operates more\\nat the sub-symbolic level, lending itself more naturally for',\n",
              " 'the former operates more at the symbolic level, lending itself\\nnaturally to explainable AI, while the latter operates more\\nat the sub-symbolic level, lending itself more naturally for\\ncomputer vision and natural language processing.\\nUnlike some other recent surveys or perspectives on neural-\\nsymbolic computation [Besold et al., 2017; d’Avila Garcez et\\nal., 2019 ], the present survey limits itself to a logical and prob-\\nabilistic perspective, which it inherits from StarAI, and to de-\\nvelopments in neural-symbolic computation that are consistent\\nwith this perspective. Furthermore, it focuses on representative\\nand prototypical systems rather than aiming at completeness\\n(which would not be possible given the fast developments in\\nthe ﬁeld). Another early overview of neural-symbolic compu-',\n",
              " 'and prototypical systems rather than aiming at completeness\\n(which would not be possible given the fast developments in\\nthe ﬁeld). Another early overview of neural-symbolic compu-\\ntation is that of [Bader and Hitzler, 2005 ]. Unlike the present\\nsurvey it focuses very much on a logical and a reasoning per-\\nspective. Today, the focus has shifted very much to learning.\\nThe following sections of the paper each describe one di-\\nmension. We summarize various neural-symbolic approaches\\nalong these dimensions in Table 1. For ease of writing, we\\ndo not always repeat the references to these approaches in the\\npaper, the table mentions the key reference for each of them.\\n2 Directed vs Undirected\\nWithin the graphical model community there is a distinction',\n",
              " 'paper, the table mentions the key reference for each of them.\\n2 Directed vs Undirected\\nWithin the graphical model community there is a distinction\\nbetween the directed andundirected graphical models [Koller\\nand Friedman, 2009 ], which has led to two distinct types of\\nStarAI systems. The ﬁrst generalizes directed models, and\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4943resembles Bayesian networks; the second generalizes undi-\\nrected models like Markov networks or random ﬁelds. The\\nkey difference between the two is that the ﬁrst class of mod-\\nels indicates a natural direction (sometimes the term “causal”\\nis used) between the different random variables, while the\\nsecond one does not.',\n",
              " 'els indicates a natural direction (sometimes the term “causal”\\nis used) between the different random variables, while the\\nsecond one does not.\\nIn StarAI, the ﬁrst category includes well-known represen-\\ntations such as plate notation [Koller and Friedman, 2009 ],\\nprobabilistic relational models (PRMs) [Friedman et al. , 1999 ],\\nprobabilistic logic programs (PLPs) [De Raedt and Kimmig,\\n2015 ], and Bayesian logic programs (BLPs) [Kersting and\\nDe Raedt, 2007 ]. Today the most typical and popular rep-\\nresentatives of this category are the probabilistic (logic) pro-\\ngrams. The second category includes Markov Logic Networks\\n(MLNs) [Richardson and Domingos, 2006 ]and Probabilistic\\nSoft Logic (PSL) [Bach et al., 2017 ]. They specify a set of\\nweighted constraints, clauses or formulae.',\n",
              " '(MLNs) [Richardson and Domingos, 2006 ]and Probabilistic\\nSoft Logic (PSL) [Bach et al., 2017 ]. They specify a set of\\nweighted constraints, clauses or formulae.\\nFrom a logical perspective, the difference amounts to using\\na form of deﬁnite clauses (as in the programming language\\nProlog) versus the use of full clausal logic or even ﬁrst order\\nlogic. On the one hand, a deﬁnite clause is an expression of the\\nformh b1^:::^bnwherehand thebiare logical atoms of\\nthe formp(t1;:::;t m), withpbeing a predicate of arity mand\\nthetibeing terms, that is, constants, variables, or structured\\nterms of the form f(t1;:::;t n), wherefis a functor and the\\ntiare again terms. On the other hand, full clausal logic also\\nallows for formulae of the form h1_:::_hm b1;:::;b n.',\n",
              " 'terms of the form f(t1;:::;t n), wherefis a functor and the\\ntiare again terms. On the other hand, full clausal logic also\\nallows for formulae of the form h1_:::_hm b1;:::;b n.\\nThe ﬁrst type of rule forms the basis of programming and\\ndatabase languages such as Prolog and Datalog. It is typically\\nused for forward or backward inference to prove that certain\\natoms hold. The second type of clause speciﬁes a more gen-\\neral relationship between two sets of atoms, the ones in the\\ncondition and in the conclusion part. While such clauses can\\nalso be used in (resolution) theorem provers, they can also be\\nviewed as constraints that relate these two sets of atoms as is\\ncommon in Answer Set Programming [Gebser et al., 2012 ].\\nThis difference reﬂects the kind of knowledge that the user has',\n",
              " 'viewed as constraints that relate these two sets of atoms as is\\ncommon in Answer Set Programming [Gebser et al., 2012 ].\\nThis difference reﬂects the kind of knowledge that the user has\\nabout the problem. With directed models, one can express that\\na set of variables has a direct “causal” inﬂuence on another\\none, while with undirected ones one expresses a kind of (soft)\\nconstraints on a set of variables, that is, that the variables are\\nrelated to one another. More details on these connections can\\nbe found in [De Raedt et al., 2016 ].\\nBorrowing this view from StarAI, we can devise a ﬁrst di-\\nmension for neural-symbolic approaches, which relies entirely\\non the logical perspective outlined above.\\nThe ﬁrst category includes systems which retain the directed',\n",
              " 'mension for neural-symbolic approaches, which relies entirely\\non the logical perspective outlined above.\\nThe ﬁrst category includes systems which retain the directed\\nnature of logical inference as they exploit backward chaining.\\nThe most prominent members of this category are NeSy sys-\\ntems based on Prolog or Datalog, such as Neural Theorem\\nProvers (NTPs) [Rockt ¨aschel and Riedel, 2017 ], NLProlog\\n[Weber et al., 2019 ], DeepProbLog [Manhaeve et al., 2018 ]\\nand DiffLog [Siet al., 2019 ]. Lifted Relational Neural Net-\\nworks (LRNNs) [ˇSourek et al., 2018 ]and@ILP[Evans and\\nGrefenstette, 2018 ]are other examples of non-probabilistic\\ndirected models, where deﬁnite clauses are compiled into a\\nneural network architecture in a forward chaining fashion. The',\n",
              " 'Grefenstette, 2018 ]are other examples of non-probabilistic\\ndirected models, where deﬁnite clauses are compiled into a\\nneural network architecture in a forward chaining fashion. The\\nsystems that imitate logical reasoning with tensor calculus,\\nNeural Logic Programming (NeuralLP) [Yang et al., 2017 ]and Neural Logic Machines (NLM) [Dong et al., 2019 ], are\\nlikewise instances of directed logic.\\nThe undirected NeSy approaches consider logic as a con-\\nstraint on the behaviour of a predictive model. A large\\ngroup of approaches, including Semantic Based regularization\\n(SBR) [Diligenti et al., 2017 ], Logic Tensor Networks(LTN)\\n[Donadello et al., 2017 ]and Semantic Loss (SL) [Xuet al.,\\n2018 ], exploits logical knowledge as a soft constraint over',\n",
              " '(SBR) [Diligenti et al., 2017 ], Logic Tensor Networks(LTN)\\n[Donadello et al., 2017 ]and Semantic Loss (SL) [Xuet al.,\\n2018 ], exploits logical knowledge as a soft constraint over\\nthe hypothesis space in a way that favours solutions con-\\nsistent with the encoded knowledge. SBR and LTN imple-\\nment predicates as neural networks and translates the pro-\\nvided logical formulas into a real valued regularization by\\nmeans of fuzzy logic, while SL uses marginal probabilities\\nof the target atoms to deﬁne the regularization term and re-\\nlies on arithmetic circuits [Darwiche, 2011 ]to evaluate it\\nefﬁciently. Similarly, another group of approaches, including\\nNeural Markov Logic Networks (NMLN) [Marra and Ku ˇzelka,\\n2019 ]and Relational Neural Machines (RNM) [Marra et al.,',\n",
              " 'efﬁciently. Similarly, another group of approaches, including\\nNeural Markov Logic Networks (NMLN) [Marra and Ku ˇzelka,\\n2019 ]and Relational Neural Machines (RNM) [Marra et al.,\\n2020 ]extend MLNs, allowing factors to be implemented\\nas neural architectures. Finally, [Rockt ¨aschel et al., 2015;\\nDemeester et al., 2016 ]compute ground atoms scores as dot\\nproducts between relation and entities embeddings; implica-\\ntion rules are then translated into a logical loss by means of a\\ncontinuous relaxation of the implication operator.\\n3 Model-based vs Proof-based Inference\\nThe distinction between directed and undirected models is\\nclosely related to the distinction between a model-theoretic\\nand proof-theoretic approach to inference. This is clear when',\n",
              " 'The distinction between directed and undirected models is\\nclosely related to the distinction between a model-theoretic\\nand proof-theoretic approach to inference. This is clear when\\nlooking at the difference between Answer Set Programming\\nand the programming language Prolog. In the model theoretic\\nperspective, one ﬁrst grounds out the clauses in the theory and\\nthen calls a SAT solver (possibly after breaking cycles), while\\nin a proof-theoretic perspective one performs a sequence of\\ninference steps in order to obtain a proof.\\nGrounding is the step whereby a clause c(or formula) con-\\ntaining variablesfV1;:::;V kgis replaced by all instances c\\x12\\nwhere\\x12is a substitutionfV1=c1;:::V k=ckgand theciare\\nconstants (or other ground terms) appearing in the domain.',\n",
              " 'taining variablesfV1;:::;V kgis replaced by all instances c\\x12\\nwhere\\x12is a substitutionfV1=c1;:::V k=ckgand theciare\\nconstants (or other ground terms) appearing in the domain.\\nThe resulting clause c\\x12is that obtained by simultaneously\\nreplacing all variables by the corresponding constants. Usu-\\nally the grounding process is optimised in order to obtain\\nonly those ground clauses that are relevant for the considered\\ninference task.\\nMany StarAI systems use logic as a kind of template to\\nground out the relational model in order to obtain a grounded\\nmodel and perform inference. This grounded model can be a\\ngraphical model, or alternatively, a ground weighted logical\\ntheory on which traditional inference methods apply, such\\nas belief propagation or weighted model counting. This is',\n",
              " 'graphical model, or alternatively, a ground weighted logical\\ntheory on which traditional inference methods apply, such\\nas belief propagation or weighted model counting. This is\\nused in well known systems such as MLNs, PSL, BLPs, and\\nPRMs. Some systems like PRMs and BLPs additionally use\\naggregates, or combining rules, in order to combine multiple\\nconditional probability distributions into one using, e.g., noisy-\\nor.\\nAlternatively, one can follow a proof or trace based ap-\\nproach to deﬁne the probability distribution and perform infer-\\nence. This is akin to what happens in probabilistic program-\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4944ming (cf. also [Russell, 2015 ]), in StarAI frameworks such as',\n",
              " 'Proceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4944ming (cf. also [Russell, 2015 ]), in StarAI frameworks such as\\nPLPs, probabilistic databases [Van den Broeck et al. , 2017 ]\\nand probabilistic uniﬁcation based grammars such as Stochas-\\ntic Logic Programs (SLPs) [Muggleton, 1996 ]. Just like pure\\nlogic supports the model-theoretic and proof-theoretic per-\\nspectives, both perspectives have been explored in parallel for\\nsome of the probabilistic logic programming languages such\\nas ICL [Poole, 2008 ]and ProbLog [Fierens et al., 2015 ].\\nThese two perspectives carry over to the neural-symbolic\\nmethods. Approaches like NTPs, DeepProblog, @ILP and\\nDiffLog are proof-based. The probabilities or certainties that',\n",
              " 'These two perspectives carry over to the neural-symbolic\\nmethods. Approaches like NTPs, DeepProblog, @ILP and\\nDiffLog are proof-based. The probabilities or certainties that\\nthese systems output are based on the enumerated proofs,\\nand they are also able to learn how to combine them. In\\ncontrast, approaches of LRNN, LTNs, RNM, NMLN, NLM\\nand NeuralLP are all based on the model-theoretic perspective.\\nLearning in these models is done through learning the (shared)\\nparameters over the ground model and inference is based on\\npossible groundings of the model.\\n4 Logic vs Probability vs Neural\\nWhen two paradigms are integrated, examining which of the\\nbase paradigms are preserved, and to which extent, tells us a lot\\nabout the strengths and weaknesses of the resulting paradigm.',\n",
              " 'When two paradigms are integrated, examining which of the\\nbase paradigms are preserved, and to which extent, tells us a lot\\nabout the strengths and weaknesses of the resulting paradigm.\\nIn StarAI, the traditional knowledge-based model construction\\napproach is to use the logic only to generate a probabilistic\\ngraphical model. Thus the graphical model can be used to de-\\nﬁne the semantics of the model and also to perform inference.\\nThis can make it more difﬁcult to understand the effects of ap-\\nplying logical inference rules such as resolution. For instance,\\nin MLNs the addition of the resolvent of two weighted rules,\\nmakes it hard to predict the effect on the distribution.\\nOn the other hand, the opposite holds for PLPs and its',\n",
              " 'in MLNs the addition of the resolvent of two weighted rules,\\nmakes it hard to predict the effect on the distribution.\\nOn the other hand, the opposite holds for PLPs and its\\nvariants. While it is clear what the effect of a logical operation\\nis, it is often harder to directly identify and exploit properties\\nsuch as conditional or contextual independencies, which are\\nneeded for efﬁcient probabilistic inference.\\nThe position on the spectrum between logic and probability\\nhas a profound inﬂuence on the properties of the underlying\\nmodel. For NeSy, the spectrum involves not only logic and\\nneural networks, but also probability. It has been argued\\nthat when combining different perspectives in one model or\\nframework, such as neural, logic and probabilistic ones, it is',\n",
              " 'neural networks, but also probability. It has been argued\\nthat when combining different perspectives in one model or\\nframework, such as neural, logic and probabilistic ones, it is\\ndesirable to have the originals or base paradigms as a special\\ncase, see also [De Raedt et al., 2019 ].\\nThe vast majority of current NeSy approaches focuses on\\nthe neural aspect (i.e., they originated as a fully neural method\\nto which logical components have been added). Some of these\\napproaches like LTNs and TensorLog [Cohen et al., 2017 ]pur-\\nsue a kind of knowledge-based model construction approach\\nin which the logic is compiled away into the neural network\\narchitecture. A different family of NeSy approaches, which\\nincludes SL and SBR, turns the logic into a regularization',\n",
              " 'in which the logic is compiled away into the neural network\\narchitecture. A different family of NeSy approaches, which\\nincludes SL and SBR, turns the logic into a regularization\\nfunction to provide a penalty whenever the desired logical\\ntheory or constraints are violated. This leads to the logic being\\ncompiled into the weights of the trained neural network.\\nA small number of NeSy methods do retain the focus on\\nlogic. Some of these methods start from existing logic (pro-\\ngramming) frameworks and extend them with primitives thatallow them to interface with neural networks and allow for\\ndifferentiable operations. Examples include DeepProbLog and\\nDiffLog. Other methods instead take an existing framework\\nand turn it into a differentiable version. The key inference',\n",
              " 'differentiable operations. Examples include DeepProbLog and\\nDiffLog. Other methods instead take an existing framework\\nand turn it into a differentiable version. The key inference\\nconcepts are mapped onto an analogous concept that behaves\\nidentically for the edge cases, but is continuous and differen-\\ntiable in non-deterministic cases. Such methods include @ILP,\\n@4[Boˇsnjak et al., 2017 ]and NTPs.\\nAn aspect that signiﬁcantly aids in developing a common\\nframework, and analysing its properties, is the development\\nof an intermediate representation language that can serve as\\na kind of assembly language [Zuidberg Dos Martires et al.,\\n2019 ]. One such idea concerns performing probabilistic infer-\\nence by mapping it onto a weighted model counting (WMC)',\n",
              " 'a kind of assembly language [Zuidberg Dos Martires et al.,\\n2019 ]. One such idea concerns performing probabilistic infer-\\nence by mapping it onto a weighted model counting (WMC)\\nproblem. This can then in turn be solved by compiling it into\\na structure (e.g. an arithmetic circuit) that allows for efﬁcient\\ninference. This has the added beneﬁt that this structure is\\ndifferentiable, which can facilitate the integration between\\nlogic based systems and neural networks. DeepProbLog, for\\nexample, uses this approach.\\n5 Semantics\\nTraditionally, StarAI combines two semantics: a logical and a\\nprobabilistic one. In the logical semantics, atoms are assigned\\na truth value in the ftrue; falseg set (i.e.f0;1g). In a proba-\\nbilistic semantics, probability is deﬁned as a measure over sets',\n",
              " 'probabilistic one. In the logical semantics, atoms are assigned\\na truth value in the ftrue; falseg set (i.e.f0;1g). In a proba-\\nbilistic semantics, probability is deﬁned as a measure over sets\\nof possible worlds, where each possible world is an assignment\\nof values to the random variables. This implies that a proba-\\nbilistic logic semantics deﬁnes probability distributions over\\nground logical interpretations, that is, over sets of ground facts.\\nProminent examples in StarAI are ProbLog (from the directed\\nside) and MLNs (from the undirected one). Incorporating\\nprobabilistic semantics into a logical one is natural when one\\nwants to perform logical reasoning under uncertainty. More-\\nover, it “only” extends Boolean logic with probabilities, thus',\n",
              " 'probabilistic semantics into a logical one is natural when one\\nwants to perform logical reasoning under uncertainty. More-\\nover, it “only” extends Boolean logic with probabilities, thus\\nit preserves the original logical semantics. However, this ex-\\ntension comes at the price of more complex inference, which\\nmakes probabilistic StarAI models intractable in large scale\\ndomains.\\nAnother approach is to turn the logical operators into real-\\nvalued functions, and in doing so relax the Boolean truth\\nvalues to the continuous [0;1]interval. This introduces the se-\\nmantics of fuzzy logic (or soft logic), which is mathematically\\ngrounded in the t-norm theory. The fuzzy semantics can be\\nused alone or in conjunction with the probabilistic one (e.g.',\n",
              " 'mantics of fuzzy logic (or soft logic), which is mathematically\\ngrounded in the t-norm theory. The fuzzy semantics can be\\nused alone or in conjunction with the probabilistic one (e.g.\\n[Bach et al., 2017 ]). The algebraic and geometric properties of\\nt-norms (including especially convexity and differentiability)\\nresults in a reduction in the complexity of logical and/or prob-\\nabilistic inference. However, differently from the probabilistic\\ncase, the semantics of the original Boolean theory is not pre-\\nserved. Indeed, the fuzziﬁcation procedure can introduce unde-\\nsirable effects. In particular, improper choices in the fuzziﬁca-\\ntion could lead to behaviours that are different from the ones\\nin the original theory [Giannini et al., 2018 ]and particular',\n",
              " 'sirable effects. In particular, improper choices in the fuzziﬁca-\\ntion could lead to behaviours that are different from the ones\\nin the original theory [Giannini et al., 2018 ]and particular\\nattention should be paid to assessing that any desired property\\nis preserved. For example, when translating the implication\\nA!Bwith its fuzzy material implication (i.e. :A_B), one\\nmay lose the transitivity property (e.g. the material implication\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4945in the minimum logic). Another class of anomalies concerns\\nthe way t-norms behave when aggregating a large number of\\nfuzzy truth degrees. An example is the n-ary Łukasiewicz\\nstrong disjunction F\\x08(x1;:::;x n) =min(1;x1+\\x01\\x01\\x01+xn).',\n",
              " 'the way t-norms behave when aggregating a large number of\\nfuzzy truth degrees. An example is the n-ary Łukasiewicz\\nstrong disjunction F\\x08(x1;:::;x n) =min(1;x1+\\x01\\x01\\x01+xn).\\nIt can evaluate to 1 (i.e. true) also when all xiare very small\\n(i.e. false), e.g. n= 10 andxi= 0:1. The use of this operator\\nwould lead to poor approximations when disjointing multiple\\natoms, e.g. in existentially quantiﬁed formulas or in the aggre-\\ngation of several alternative proofs. [van Krieken et al., 2020 ]\\nanalyse similar issues, also in connection to differentiability.\\nNeural-symbolic approaches can easily be categorized along\\nthe same lines. Neural enhancements of the logic semantics\\neither use neural networks to turn perceptive input to a logical\\natom, or relax the logical reasoning through tensor calculus.',\n",
              " 'the same lines. Neural enhancements of the logic semantics\\neither use neural networks to turn perceptive input to a logical\\natom, or relax the logical reasoning through tensor calculus.\\nAn instance of the former is ABL [Daiet al., 2019 ], which use\\nlogical abduction to provide the feedback for a neural model\\nprocessing the perceptive input. Tensor calculus approaches,\\nsuch as NLM and NeuralLP, interpret predicates as tensors\\ngrounded over all constants in a domain and interpret clauses\\nas a product of those matrices.\\nNeural enhancements of the probabilistic semantics usually\\nparameterize the underlying distribution in terms of neural\\ncomponents. In particular, DeepProbLog exploits neural pred-\\nicates to compute the probabilities of probabilistic facts as the',\n",
              " 'parameterize the underlying distribution in terms of neural\\ncomponents. In particular, DeepProbLog exploits neural pred-\\nicates to compute the probabilities of probabilistic facts as the\\noutput of neural computations over vectorial representations\\nof the constants, which is similar to SL in the propositional\\ncounterpart. NMLN and RNM use neural potentials in order\\nto implement factors (or their weights) as neural networks.\\n[Rockt ¨aschel et al., 2015 ]computes marginal probabilities as\\nlogistic functions over similarity measures between embed-\\ndings of entities and relations.\\nIn neural enhancements of the fuzzy semantics, neural net-\\nworks produce continuously-valued truth assignments. The\\ndifferentiability of the t-norms allows to easily integrate neu-',\n",
              " 'In neural enhancements of the fuzzy semantics, neural net-\\nworks produce continuously-valued truth assignments. The\\ndifferentiability of the t-norms allows to easily integrate neu-\\nral frameworks. In particular, SBR and LTN turn atoms into\\nneural networks taking as inputs the feature representation\\nof the constants and returning the corresponding truth value.\\nSimilarly, in LRNN, @ILP, DiffLog and [Wang and Pan, 2019 ],\\nthe scores of the proofs are computed by using fuzzy logic\\nconnectives.\\nFinally, a large class of methods [Minervini et al., 2017;\\nDemeester et al., 2016; Cohen et al., 2017; Weber et al., 2019 ]\\nrelaxes logical statements in a numeric way, without giving\\nany other speciﬁc semantics. Here, atoms are assigned scores\\ninRcomputed by a neural scoring function over embeddings.',\n",
              " 'relaxes logical statements in a numeric way, without giving\\nany other speciﬁc semantics. Here, atoms are assigned scores\\ninRcomputed by a neural scoring function over embeddings.\\nNumerical approximations are then applied either to combine\\nthese scores according to logical formulas or to aggregate\\nproofs scores. The resulting neural architecture is usually\\ndifferentiable and, thus, trained end-to-end. It is however hard\\nto interpret the numbers generated by such approaches.\\n6 Structure vs Parameter Learning\\nStarAI distinguishes between two types of learning: structure\\nlearning, which corresponds to learning the logical clauses of\\nthe model [Kok and Domingos, 2005 ], and parameter learning\\nin which the probabilities or weights of the clauses have to be',\n",
              " 'learning, which corresponds to learning the logical clauses of\\nthe model [Kok and Domingos, 2005 ], and parameter learning\\nin which the probabilities or weights of the clauses have to be\\nestimated [Gutmann et al., 2008; Lowd and Domingos, 2007 ].\\nThe former is typically achieved by means of a combinatorialsearch over the space of possible clauses, while in the latter\\none an expert user provides a set of informative clauses for\\nwhich only the probabilities have to be estimated.\\nLearning in NeSy approaches blurs this distinction and\\nis positioned somewhere mid-ground: the model structure\\nis learned though parameter learning. In contrast to StarAI\\nparameter learning in which the user carefully selects the\\ninformative clauses, the set of clauses in NeSy approaches is',\n",
              " 'is learned though parameter learning. In contrast to StarAI\\nparameter learning in which the user carefully selects the\\ninformative clauses, the set of clauses in NeSy approaches is\\ntypically enumerated from the user-provided rule templates of\\npredeﬁned complexity. As such, the enumerated rules contain\\nnoisy and erroneous patterns that are corrected by learning the\\ncorresponding probabilities or weights. The structure learning\\nis therefore not performed explicitly as none of the given rules\\nis removed. While it is certainly possible to extract the most\\nimportant clauses, the inference is still performed considering\\nall the enumerated clauses. Examples of such systems include\\nNTPs,@ILP, DeepProbLog, NeuralLP and DiffLog. A related\\nway of learning the structure is that of program sketching,',\n",
              " 'all the enumerated clauses. Examples of such systems include\\nNTPs,@ILP, DeepProbLog, NeuralLP and DiffLog. A related\\nway of learning the structure is that of program sketching,\\nin which a user provides a sketch of the target model and\\nleaves certain parts of the model unspeciﬁed. The learning\\ntask corresponds to ﬁlling the blanks. NeSy systems based on\\nsketching, such as DeepProbLog and @4, perform a simpliﬁed\\nversion of sketching in which they ﬁll in a single operation\\ninstead of an entire program.\\nA substantial number of approaches tries to leverage the\\nbest of both worlds. These ideas include using neural models\\nto guide the symbolic search [Kalyan et al., 2018; Ellis et\\nal., 2018a; Valkov et al., 2018 ], or using a neural model to',\n",
              " 'best of both worlds. These ideas include using neural models\\nto guide the symbolic search [Kalyan et al., 2018; Ellis et\\nal., 2018a; Valkov et al., 2018 ], or using a neural model to\\nproduce a program that is then executed symbolically [Ellis et\\nal., 2018b; Mao et al., 2019 ].\\n7 Symbols vs Sub-symbols\\nPerhaps the biggest difference between StarAI and neural\\nmethods is how they represent entities. StarAI generally repre-\\nsents entities by constants (symbols). However, neural meth-\\nods are unable to represent symbols directly and exactly, and\\ntherefore represent them with sub-symbolic formats, such as\\nvectorized representations. For instance, vectorized represen-\\ntations can be created through one-hot encodings, inherent\\nnumerical properties of symbols (e.g. the pixel data of an',\n",
              " 'vectorized representations. For instance, vectorized represen-\\ntations can be created through one-hot encodings, inherent\\nnumerical properties of symbols (e.g. the pixel data of an\\nimage), or by learning a mapping from one-hot encodings to\\na dense feature space. This, of course, has an impact on the\\ngeneralizability of the system towards unseen entities, as no\\nvectorized representation is available for an unseen entity.\\nAn especially interesting aspect of NeSy methods is that\\nthey combine the best of both worlds by introducing a vari-\\nety of ways to combine symbols and sub-symbols for task\\nrepresentation and reasoning. The idea of mapping entities\\nonto sub-symbols is made very explicit in LTNs, where in\\na ﬁrst step, all symbols are replaced with sub-symbols. In',\n",
              " 'representation and reasoning. The idea of mapping entities\\nonto sub-symbols is made very explicit in LTNs, where in\\na ﬁrst step, all symbols are replaced with sub-symbols. In\\nDeepProbLog, entities are represented using symbols, but they\\nsometimes have sub-symbolic representations that are only\\nused inside the neural networks. Similarly, in [Lippi and Fras-\\nconi, 2009 ]and RNM, MLNs are conditioned on a feature\\nrepresentation of constants (e.g. images, audio signals). Fi-\\nnally, among those models exploiting learned embeddings,\\nwe ﬁnd [Rockt ¨aschel et al., 2015; Minervini et al., 2017;\\nDemeester et al., 2016 ].\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4946A powerful and elegant mechanism for reasoning about',\n",
              " 'Demeester et al., 2016 ].\\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\\nSurvey Track\\n4946A powerful and elegant mechanism for reasoning about\\nsymbols matching in logic is uniﬁcation. For instance, the\\natomic expressions p(a;Y)andp(X;b)can be uniﬁed using\\nthe substitutionfX=a;Y=bg. Uniﬁcation not only works\\nfor constants but also for structured terms f(t1;:::;t n)wheref\\nis a structured term and the tiare constants, variables or struc-\\ntured terms themselves. While uniﬁcation is not supported by\\nstandard neural networks, matching of the symbols can be per-\\nformed based on their similarity in embedding space. Entities\\nare typically embedded in some metric space, and represented\\nthrough their embeddings, that is, through sub-symbols. Rea-',\n",
              " 'formed based on their similarity in embedding space. Entities\\nare typically embedded in some metric space, and represented\\nthrough their embeddings, that is, through sub-symbols. Rea-\\nsoning typically proceeds by performing algebraic operations\\n(such as vector addition) on these embeddings, and consider-\\ning the similarity between two entities by using their distance\\nin embedding space. It is quite interesting to see to what extent\\ncurrent neural-symbolic approaches support uniﬁcation on the\\none hand, and to what extent the use of embeddings has been\\nintegrated into the neural-symbolic logics as a kind of soft\\nequality or uniﬁcation\\nThis idea was implemented in NTPs and NLProlog as softor\\nweak uniﬁcation. In these systems, two entities can be uniﬁed',\n",
              " 'equality or uniﬁcation\\nThis idea was implemented in NTPs and NLProlog as softor\\nweak uniﬁcation. In these systems, two entities can be uniﬁed\\nif they are similar, and not just if they are identical. As such,\\nthis system can interweave both symbols and sub-symbols\\nduring inference. For each entity, an embedding is learned and\\ntheir similarity is determined based on the distance between\\nthe embeddings using a radial basis function. However, this\\npotentially adds a lot of different proof paths, which can result\\nin computational issues for larger programs. This problem\\nwas solved in later iterations of the system [Minervini et al.,\\n2020 ].\\n8 Type of Logic\\nStarAI approaches have explored various types of logical rep-\\nresentations, following a natural ordering [De Raedt, 2008;',\n",
              " '2020 ].\\n8 Type of Logic\\nStarAI approaches have explored various types of logical rep-\\nresentations, following a natural ordering [De Raedt, 2008;\\nFlach, 1994 ]starting with propositional logic (symbols with-\\nout arguments), to relational logic (with only constants and\\nvariables as terms, without any structured terms) which forms\\nthe basis for the Datalog database language, to general ﬁrst\\norder logic, and then to logic programs as in the program-\\nming language Prolog. Logic programs are usually re-\\nstricted to deﬁnite clauses. The semantics of a deﬁnite\\nclause program is given by its least Herbrand model, the\\nset of all ground facts that are logically entailed by the pro-\\ngram. This contrasts with the standard semantics of ﬁrst order',\n",
              " 'clause program is given by its least Herbrand model, the\\nset of all ground facts that are logically entailed by the pro-\\ngram. This contrasts with the standard semantics of ﬁrst order\\nlogic that would also allow for other models. This differ-\\nence carries over to StarAI, where probabilistic logic pro-\\ngrams and Markov Logic inherit their semantics from logic\\nprogramming, respectively ﬁrst order logic. This explains,\\nfor instance, why Markov Logic’s semantics boils down to\\na maximum entropy approach when a theory has multiple\\nmodels (such as a_b), cf. [De Raedt and Kimmig, 2015;\\nDe Raedt et al., 2016 ]for more details. On the other hand,\\nlogic programs are also the basis for the programming lan-\\nguage Prolog, which implies that they can be used to specify',\n",
              " 'De Raedt et al., 2016 ]for more details. On the other hand,\\nlogic programs are also the basis for the programming lan-\\nguage Prolog, which implies that they can be used to specify\\ntraditional programs such as sorting and data structures such\\nas lists through structured terms. This is relevant especially\\nfor those approaches to neural-symbolic computation that are\\nused to synthesize programs from examples.NeSy approaches follow the same natural expressivity order\\nof the underlying logics. For instance, SL focuses only on\\nthe propositional setting. On the other hand, @ILP, NTPs and\\nDiffLog are based on Datalog, which belongs to relational\\nlogic segment. LTNs and SBR use fuzzy logic to translate a\\ngeneral ﬁrst-order logic theory into a training objective, either',\n",
              " 'DiffLog are based on Datalog, which belongs to relational\\nlogic segment. LTNs and SBR use fuzzy logic to translate a\\ngeneral ﬁrst-order logic theory into a training objective, either\\nisolated or in conjunction with a supervised criterion. Just like\\nMarkov Logic, also RNM and NMLN use ﬁrst-order logic to\\ngenerate a random ﬁeld. Finally, DeepProbLog, NLProlog and\\nLRNN are examples of neural-symbolic logic programming\\nframeworks.\\nThe chosen type of logic has a signiﬁcant impact on infer-\\nence and learning. The more expressive a logic, the harder\\nthe inference and learning become. For instance, for structure\\nlearning, the space of possible clauses for structure learning\\ntypically becomes exponentially larger as a more expressive\\nclass of logic is used. At the same time, many theories re-']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset into the vector store"
      ],
      "metadata": {
        "id": "Felch9g7iac7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store.add_texts(texts[:50])\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts[:50]))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cszHVoLiZ3V",
        "outputId": "873b19a7-8a4e-443a-ac4a-d72a17ab10da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 50 headlines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the QA cycle\n",
        "\n",
        "Simply run the cells and ask a question -- or `quit` to stop. (you can also stop execution with the \"▪\" button on the top toolbar)"
      ],
      "metadata": {
        "id": "fdbHM_T0jGMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:150]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddWtevFKix_s",
        "outputId": "c50a920e-ee25-44e1-eb0e-fdfa3e8a384e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your question (or type 'quit' to exit): How do Statistical Relational AI and Neuro-Symbolic AI differ in their fundamental goals?\n",
            "\n",
            "QUESTION: \"How do Statistical Relational AI and Neuro-Symbolic AI differ in their fundamental goals?\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER: \"Statistical Relational AI and Neuro-Symbolic AI have different fundamental goals. The former focuses more on logical reasoning and is better suited for explainable AI, while the latter focuses more on sub-symbolic processing and is better suited for tasks like computer vision and natural language processing.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [0.9440] \"From Statistical Relational to Neural-Symbolic Artiﬁcial Intelligence\n",
            "Luc De Raedt1;2,Sebastijan Duman ˇci´c1,Robin Manhaeve1and Giuseppe Marra1\n",
            "1KU L ...\"\n",
            "    [0.9301] \"the former operates more at the symbolic level, lending itself\n",
            "naturally to explainable AI, while the latter operates more\n",
            "at the sub-symbolic level,  ...\"\n",
            "    [0.9251] \"by positioning a wide variety of StarAI and NeSy systems\n",
            "along these dimensions and pointing out analogies between\n",
            "them. This provides not only new in ...\"\n",
            "    [0.9208] \"best of both worlds. These ideas include using neural models\n",
            "to guide the symbolic search [Kalyan et al., 2018; Ellis et\n",
            "al., 2018a; Valkov et al., 20 ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): quit\n"
          ]
        }
      ]
    }
  ]
}