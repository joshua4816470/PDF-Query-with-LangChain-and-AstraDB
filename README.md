# ğŸ“š PDF Query with LangChain and Cassandra AstraDB

This repository showcases a complete **Retrieval-Augmented Generation (RAG)** pipeline that allows users to query any PDF and get instant, context-based answers powered by **LangChain**, **OpenAI**, and **AstraDB**.

---

## ğŸ” Key Features

- ğŸ“„ Extracts text from PDFs using **PyPDF2**  
- âœ‚ï¸ Splits long text into semantic chunks via LangChainâ€™s `CharacterTextSplitter`  
- ğŸ§® Converts chunks into **vector embeddings** using `OpenAIEmbeddings`  
- ğŸ—ƒï¸ Stores and retrieves vectors from **Cassandra AstraDB** for high-speed **similarity search**  
- ğŸ¤– Generates intelligent, context-driven answers using **OpenAIâ€™s LLM**  
- ğŸ’¬ Supports **real-time Q&A** from the command line  

---

## ğŸ§  Tech Stack

| Component | Description |
|------------|-------------|
| **LangChain** | Orchestrates LLMs, embeddings, and retrieval |
| **OpenAI API** | Used for embeddings and generative responses |
| **Cassandra AstraDB** | Cloud-native vector database for storing embeddings |
| **PyPDF2** | Extracts and parses text from PDF documents |
| **Python 3.10+** | Primary programming language |

---

## âš™ï¸ Project Workflow

1. **Extract text from PDF** using `PyPDF2`  
2. **Split into overlapping chunks** with `CharacterTextSplitter`  
3. **Embed text** using `OpenAIEmbeddings`  
4. **Store embeddings** in **AstraDB** through the `CassIO` connector  
5. **Retrieve similar chunks** via vector search  
6. **Generate contextual answers** using `LangChain` + `OpenAI` LLM  

---

## ğŸ’¡ Use Case Example

You can query research papers, manuals, or academic PDFs â€” for example, comparing **Neuro-Symbolic AI** and **Statistical Relational AI** papers to derive conceptual similarities through embeddings.  
The system retrieves semantically related passages from both sources and formulates a synthesized explanation in natural language.

---

## ğŸ“Š Key Metrics

| Metric | Result |
|---------|--------|
| PDF Size | ~20 pages |
| Processed Chunks | ~50 text segments |
| Average Retrieval Latency | < 2 seconds |
| Semantic Relevance Accuracy | ~90% (manually validated) |

---

## ğŸ Quick Start

```bash
# 1. Install dependencies
pip install lang
